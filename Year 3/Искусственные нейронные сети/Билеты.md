# Основные понятия нейронных сетей (НС): 
## Преимущества НС
Нейронная сеть - математическая модель, построенная по аналогии с биологическими нейронными сетями, т.е. мозгом. В основе нейронных сетей лежат искуственные нейроны- узлы сети, представляющие собой нелинейную функцию, принимающую на вход линейную комбинацию всех входных сигналов
![[Assets/basic-nn.png]]
### Понятия:
#### Нейрон
Нейрон - узел НС, принимающий на вход линейную комбинацию всех входных сигналов и применяющий к ним функцию активации
#### Слои нейронов 
Нейроны зачастую расположены в несколько слоёв:
- Входной слой - слой, принимающий внешние данные
- Скрытые слои - промежуточные слои, обрабатывающие данные
- Выходной слой - слой, возвращающий результат
Иногда нейронные сети бывают двухслойные, однослойные и бесслойные
#### Функция активации
Функция активации - функция, определяющая выходной сигнал нейрона
![[../../activation-function.png]]
#### Веса
Параметры, настраиваемые при обучении
### Преимущества 
1. Обучение - нейронные сети способны автоматически выявлять закономерности в входных данных, которые для традиционных алгоритмов необходимо программировать
2. Гибкость - одинаковые типы нейросетей могут быть использованы для разных задач, а традиционные алгоритмы узкоспециализированы
3. Работа с неструктурированными данными - НС эффективно обрабатывают изображения, аудио, видео, текст, где данные не имеют чёткой табличной структуры
4. Устойчивость к шуму - НС могут обобщать и корректно работать с зашумлёнными или неполными данными
5. Масштабируемость - во многих случаях, чем больше данных, тем лучше работает нейросеть.
6. Автоматизация задач без алгоритмических решений
7. Параллелизация - в большинстве случаев, НС обрабатывают данные на GPU-ядрах, давая доступ к параллелизации
## Модели нейронов
### Нейрон
Нейрон - базовая вычислительная единица нейронной сети, вдохновленная биологическим нейроном. Он принимает входные сигналы, обрабатывает их и передает выход дальше. Математически представляет собой взвешенный сумматор с одним выходом, значение которого определяется через матрицу весов
$$
y = f(u)\;\;where\;\;u=\sum\limits^{n}_{i=1}w_{i}x_{i}+w_{0}x_{0}
$$
Где $x_{i},w_{i}$ - сигналы на входах нейрона и веса входов, $u$ - индуцированное локальное поле, $f(u)$ - активационная функция.
#### Структура нейрона
![[Assets/neuron-structure.png]]
Нейроны состоят из
1. Входов $x_{1}..x_{n}$ - выходы других нейтронов
2. Весов $w_{1}..w_{n}$ - коэффициенты важности каждого входа
3. Функций сумматора и активации
4. Выходов (например, других нейронов)
#### Виды нейронов
##### По топологии
1. Входные - принимают вектор данных на основе изначально переданных данных
2. Выходные - преобразуют данные НС для вывода
3. Промежуточные - основные нейроны сети
##### По связности
В зависимости от вида НС, нейрон может быть связан со всеми входами и выходами, а может быть связан только с частью (условной локальной областью)
## Направленные графы для представления нейронных сетей
Нейронные сети можно представить как направленные графы, где каждая вершина - это нейрон, набор вершин - слой, а рёбра представляют собой передачу данных между нейронами с весами. Такие графы позволяют визуализировать структуру нейронной сети.

Также существуют графовые нейронные сети (GNN), которые принимают графы на вход
### Типы графов
#### Ациклические направленные графы
В графах нет циклов, данные движутся только в одном направлении. Используются для [[#Многослойный перцептрон|MLP]] и CNN сетей
![[Assets/acyclic-graph.png]]
#### Циклические графы
Содержат обратные связи, позволяющие учитывать "память" - предыдущие состояния. Используются для RNN, LSTM, GRU и трансформеров
![[Assets/rnn-graph.png]]
### Преимущества
- Удобство описания архитектуры: можно моделировать сложные топологии
- Автоматическое дифференцирование: фреймворки (TensorFlow, PyTorch) используют графы для расчёта градиентов
- Анализ зависимостей: помогает оптимизировать вычисления
## Обратная связь
Обратная связь - механизм передачи информации от последующих слоёв к предыдущим. Это позволяет сети учитывать предыдущие состояния или контекст
### Типы
#### Рекуррентные связи
Используются в RNN. Выход нейрона со скрытого слоя передаётся обратно в этот же слой или в более ранние слои
#### Обратное распространение ошибки (backpropagation through time)
Используется для распространения ошибки по слою и по предыдущим слоям, где распространение ошибки происходит за счёт высчитывания градиента функции потери для всех параметров сети.
#### Обратные связи для памяти
Используются для решения проблемы "исчезающих" градиентов (сдвигу градиентов к нулю в рекуррентных сетях с backpropagation). Определяют, какие пути должны быть сохранены в памяти
### Обратные связи для внимания
Используются для сетей-трансформеров для реализации веса внимания, который зависит от всех элементов последовательности.
## Архитектура НС
В рамках архитектуры НС определяются
1. Структура слоёв и их взаимосвязи
2. Типы нейронов и функции активации
3. Направление потока данных
### Основные компоненты
- Входной слой - слой, принимающий внешние данные
- Скрытые слои - промежуточные слои, обрабатывающие данные
- Выходной слой - слой, возвращающий результат
![[Assets/basic-nn.png]]
### Типы архитектур
1. Полносвязные сети (FNN) - классические сети, используемые для задач классификации
2. Сверточные сети (CNN) - содержат сверточные слои для выделения и свертывания данных, слои пулинга для уменьшения количества слоёв данных, полносвязные слои для классификации, а также поле приёма для приёма части предыдущего слоя
3. Рекуррентные сети (RNN, LSTM, GRU) - имеют циклические связи для запоминания состояния и истории
4. Трансформеры - имеют связи для расчета весов внимания в сети
## 6. Основные понятия нейронных сетей (НС): представление знаний
Представление знаний - способ кодирования информации для отображения взаимосвязи в данных, весов связей.
### Методы представлений
1. Как носитель знаний (каждое ребро графа НС имеет вес)
2. Векторные представления (дискретные данные преобразуются в непрерывные векторы со связями)
3. Активации скрытых слоёв (иерархические представления связей)
### Уровни представления
1. Низкоуровневые признаки - данные начальных слоёв сети
2. Высокоуровневые признаки - данные более глубоких слоёв сети
### Подходы к представлению
1. Распределённые - паттерны активации группы нейронов
2. Локальные - конкретный нейрон или группа отвечает за признак
3. Гибридные - смешение распределённых и локальных

# 7. Нейронные сети и искусственный интеллект
# Основные подходы к обучению
Обучение нейронных сетей - процесс настройки параметров сети для минимизации ошибок предсказания. Существует несколько подходов к обучению
## Обучение, основанное на коррекции ошибок
Основная идея - минимизация разницы между предсказаниями модели и правильными ответами
### Этапы
1. Прямое распространение - данные проходят через сеть без коррекции
2. Вычисление ошибки - сравнение предсказания модели с правильным ответом на основе MSE или других формул
3. Обратное распространение - передача ошибки обратно по сети для вычисление градиентов для весов
4. Коррекция весов
### Методы коррекции
1. Градиентный спуск - вычисление нового веса по формуле $w_{new}=w_{old}-\eta{}\nabla{}Q_{i}(w)$, где $\eta$ - темп обучения, $\nabla$ - градиент (производная) функции потери
2. Стохастический градиентный спуск - замена градиента приблизительным для увеличения скорости вычислений ценой точности с помощью функции $w_{new}=w_{old}-\frac{\eta}{n}\sum\limits^{n}_{i=1}\nabla{}Qi(w_{old})$
3. Адаптивная оптимизация - подстаривания скорости обучения для каждого параметра.
## Обучение на основе памяти
Обучение на основе памяти - подход, в рамках которого нейросеть хранит информацию из обучения для улучшения предсказаний, что позволяет быстрее адаптироваться без переобучения
### Методы
1. k Nearest Neighbors - классификация на основе схожих с обучающей выборкой примеров
2. Long short-term memory + Gated recurrent units - рекуррентные сети с памятью для хранения или забывания некоторых данных сети с целью коррекции.
3. Neural Turing Machine - рекуррентная сеть, объединённая с внешней памятью и использующая механизмы внимания и памяти для работы с данными
4. Differentiable Neural Computer - расширение NTM с матричной памятью
5. Memory-augmented Neural Network - вид мета-модели (обучение на основе данных об обучении) для быстрого энкодинга информации и быстрой адаптации
## Обучение Хебба
Обучение на основе построения связей между нейронами при их совместной активации.
Вес связи между нейронами рассчитывается следующим образом:
$$\Delta{}w_{ij}=\eta{}\cdot{}x_{i}\cdot{}y_{i}$$
где $w$ - вес связи, $\eta$ - темп обучения, $x_{i}$ - входной сигнал, $y_{i}$ - выходной сигнал.
## Конкурентное обучение
Тип неконтроллируемого обучения, где нейроны "соревнуются" за право активироваться в ответ на входные данные. Побеждают только наиболее похожие на входные данные нейроны (Best matching unit). BMU выбирается на основе наименьшего расстояния между входными данными и весом нейрона
### Алгоритмы
1. Самоорганизующиеся карты - нейроны располагаются на сетке, веса победившего нейрона обновляются по правилу $\Delta{}w_{ij}=\eta\cdot{}h(i, i*)\cdot{}(x_{j}-w_{ij})$, где $h(i, i*)$ - функция соседства, $i*$ - расстояние до победителя
2. Квантования вектора обучения - классификация на основе прототипов. Победитель обновляется путём добавления/убавления $\eta(x - w_{i})$
### Применение
Кластеризация, сжатие данных
## Обучение Больцмана
Стохастический метод обучения с использованием статистической физики. Используется в машинах Больцмана
Использует функцию энергии для состояния нейронов
$$E=−\sum\limits_ {i<j}w_{ij​}s_{i}​s_{j}​−\sum\limits_{i}​b_i​s_i​,$$
А также функцию вероятности активации
$$p(s)=\frac{1}{1+exp\frac{-\Delta{}E_{i}}{k_{B}T}}$$
где $kB$ - константа Больцмана
### Алгоритм обучения
Использует контрастивную дивергенцию
1. В фазе данных фиксируются видимые нейроны на обучающихся данных, скрытые обновляются по вероятности, измеряются корреляции данных
2. В фазе реконструкции сеть работает "свободно", измеряются корреляции реконструкции
3. Затем веса обновляются по формуле $\Delta{}w_{ij}=\eta{}(\langle{}s_{i}s_{j}\rangle{}_{data}-\langle{}s_{i}s_{j}\rangle{}_{recon})$
## Обучение с учителем
Алгоритм обучается на размеченных данных. Для этого используется: 
1. Выборка с множеством пар $x_{i},y_{i}$, где $x$ - входной вектор признаков, $y$ - целевое значение
2. Модель - функция $f(x)$, которая настраивается на точность ответов
3. Функция потерь - мера ошибки предсказания (обычно - MSE)
4. Алгоритм оптимизации - метод обновления параметров модели (зачастую - форма градиентного спуска)
### Этапы
1. Подготовка данных - стандартизация и нормализация данных с разделением выборок
2. Выбор модели
3. Обучение - минимизация функции потерь на обучающей выборке
4. Оценка модели
### Применение
1. Классификация данных (распределение объектов по категории)
2. Регрессия (предсказание непрерывного значения)
## Обучение без учителя
Алгоритм анализирует неразмеченные данные и выявляет скрытые структуры и закономерности
### Применение
1. Кластеризация (разделение данных на разные между собой группы)
2. Поиск аномалий
3. Нахождение ассоциаций
## Задачи обучения
1. Классификация - отнесение входных данных к предопределённым классам
2. Регрессия - предсказание непрерывного значения
3. Кластеризация - разделение данных на неопределённые классы
4. Генерация данных
5. Рекомендательные системы
6. Обработка последовательностей
7. Детекция и сегментация
8. Обработка естественного языка
# Однослойный перцептрон
Однослойный перцептрон – это простейшая искусственная нейронная сеть, состоящая из одного слоя искусственных нейронов. Он был предложен Фрэнком Розенблаттом в 1957 году и является основой для более сложных архитектур нейронных сетей. Содержит только один скрытый слой нейронов. Функция активации обычно либо пороговая, либо линейная, либо сигмоида
## Адаптивная фильтрация
Адаптивный фильтр - система весов, подстраивающаяся под входной сигнал. В случае однослойного перцептрона, реализуется следующая линейная комбинация входов
$$y(n)=\sum\limits^{N-1}_{i=0}w_{i}(n)\cdot{}x(n-i)=w^{T}(n)\cdot{}x(n)$$
где $y(n)$ выход фильтра на шаге $n$, $w(n)$ - вектор весов, $x(n)$ - вектор входных сигналов
### Адаптация весов
Используются часто алгоритм наименьших квадратов
![[Assets/Pasted image 20250527105844.png]]

Ошибка фильтрации высчитывается как $e(n)=d(n)-y(n)$, где $d(n)$ - наименьший сигнал. Веса обновляются с помощью формулы $w(n+1)=w(n)+\mu{}\cdot{}e(n)\cdot{}x(n)$, где $\mu$ - шаг обучения (коэффициент темпа)
### Применение
1. Подавление шумов и предсказание сигналов
2. Идентификация
## Методы оптимизации
Оптимизация - настройка параметров модели для минимизации функции потерь и улучшения способности модели решать поставленную задачу

Однослойные перцептроны можно оптимизировать следующими способами
1. Градиентный спуск
2. Метод наименьших квадратов (аналитическое решение линейной регрессии по формуле $w=(X^{T}X)^{-1}X^{T}y$)
3. Правило Хебба - используется формула Хебба $\Delta{}w_{ij}=\eta{}\cdot{}x_{i}\cdot{}y_{i}$
4. Правило перцептрона - обновление веса только при ошибке классификации по формуле $\Delta{}w_{ij}=\eta{}\cdot{}(y - \widehat{y})\cdot{x}$
5. Метод опорных векторов - использование функции потерь hinge-loss - $l(y)=max(0, 1-y\cdot{}y)$
## Фильтр на основе метода наименьших квадратов
Однослойный перцептрон, использующий метод наименьших квадратов (МНК) для обучения, по сути, представляет собой линейный классификатор или регрессор, где веса подбираются так, чтобы минимизировать сумму квадратов ошибок между предсказанными и истинными значениями.

МНК решаеттся как $$w=(X^{T}X)^{-1}X^{T }y$$
где $X$ - матрица признаков $m\cdot{}(n+1)$ где $m,n$ - число примеров и признаков; $y$ - вектор целевых значений; $w$ - вектор весов.

Применяется для линейной регрессии ($y=w^Tx$) и классификации (ступенчатая классификация в зависимости от то, больше ли $y$ единицы)
## Алгоритм минимизации среднеквадратической ошибки
Перцептрон можно обучить для минимизации среднеквадратичной ошибки (MSE)

Для нахождения веса $w$ и смещения $b$ можно использовать следующую формулу: $$E(w, b)=\frac{1}{2N}\sum\limits^{N}_{i=1}(y_{i}\widehat{y_{i}})^{2}$$
### Алгоритм решения
1. Вычисление градиента по весам и смещению - $\frac{dE}{dw}=\frac{-1}{N}\sum\limits^{N}_{i=1}(y_{i}\widehat{y_{i}})x_{i}$ и $\frac{dE}{db}=\frac{-1}{N}\sum\limits^{N}_{i=1}(y_{i}\widehat{y_{i}})$
2. Обновление весов - $w_{new}=w_{old}-\eta{dw},\,b_{new}=b_{old}-\eta{\frac{dE}{db}}$
3. Повторение 1-2 до сходимости
## Перцептрон Розенблатта
Перцептрон Розенблатта - модель Франка Розенблатта, разработанная в 1957 году. Состоит из одного слоя искуственных нейронов, входного слоя, весовых коэффициентов и пороговой (ступенчатой или сигмоидной) функции активации

Обучение по правилу Розенблатта происходит по следующей простой формуле: $w_{i}^{new}=w_{i}^{old}+\eta{}\cdot{}(d-y)\cdot{x_{i}}$, где $d$ - желаемый выход, $y$ - текущий.

Является прототипом для следующих перцептронов и может использоваться для распознавания паттернов и простой классификации изображений
# Многослойный перцептрон
Многослойный перцептрон (MLP) - вариация перцептрона, имеющая несколько скрытых слоёв. Использует линейное преобразование и нелинейную функцию преобразования. Функция активации зависит от задачи - при регрессии используется линейная, для классификации - сигмоидная или softmax.
![[Assets/multilayer-perceptron.png]]
## Алгоритм обратного распространения ошибки
Метод минимизации ошибки сети путём коррекции весов связей между нейронами с помощью градиентного спуска
### Этапы
1. Прямое распространение - прохождение данных напрямую через сеть с получением предсказания на выходе. Каждый нейрон скрытого слоя вычисляет взвешенную сумму входов $z_{j}=\sum\limits_{i}w_{ji}x_{i}+b_{j}$, затем применяется функция активации (например, $a_{j}=\sigma(z_{j})$) и вычисляется выход сети
2. Вычисление ошибки - вычисление ошибки формулой по типу MSE ($E=\sum\limits_{k}(y_{k}-t_{k})^{2}$)
3. Обратное распространение ошибки, то есть вычисление градиентов ошибки для весов и корректирование весов
Для выходного слоя ошибка нейрона вычисляется как $\Delta{k}=(y_{k}-t_{k})\cdot{}\sigma'(z_{k})$
Корректировка весов выходного слоя происходит с помощью функции $\Delta{}w_{kj}=-\eta{}\cdot{}\Delta{}k\cdot{}a_{j}$

Для скрытого слоя ошибка нейрона вычисляется как $\Delta_{j}=\sigma'(z_{j})\sum\limits_{k}\Delta_{k}w_{kj}$
Корректировка весов скрытого слоя происходит с помощью функции $\Delta{}w_{ji}=-\eta\cdot{}\Delta_{j}\cdot{x_{i}}$

4. Обновление весов происходит с помощью добавления корректирующего веса к старому весу ($w_{new}=w_{old}+\Delta{w}$)
## Обратное распространение ошибки и дифференцирование
Обратное распространение ошибки - метод минимизации ошибки сети путём коррекции весов связей между нейронами с помощью градиентного спуска
### Этапы
1. Прямой проход - данные проходят через сеть напрямую, вычисляется предсказание. Ошибка вычисляется как разница между предсказанием и истинным значением (например, используя MSE).
2. Обратный проход - Градиенты ошибки вычисляются по всем весам сети, начиная с выходного слоя. Веса корректируются на основе градиента
### Вычисление градиента
$$\frac{d{L}}{d{w}}=\frac{dL}{dz}\cdot{} \frac{dz}{d(w_{1}x_{1}+w_{2})}\cdot{} \frac{d(w_1x_{1}+...)}{dw_{1}}=\delta\cdot{}\sigma'(a)\cdot{}x_{1}$$
где $z = \sigma(w_{1}x_{1}+w_{2}x_{2}+b)$ - выход нейрона, $\nabla{L_{z}}$ - градиент от следующего слоя, $a = w_{1}x_{1}+w_{2}x_{2}+b$ - взвешенная сумма до активации, $\sigma'(a)$ - производная функции активации
## Обучение методом обратного распространения
Обучение многослойного перцептрона состоит из
1. Инициализации весов - инициализации $w$ и $b$ со случайными малыми значениями (методами по типу Xavier initialization) с целью отсутствия симметрии градиентов и корректности обучения.
2. Прямое распространение - входные данные проходят через сеть, где выходные данные выглядят как $z^{(I)}=W^{(I)}\cdot{a^{(I-1)}}+b^{(I)}$ на основе чего вычисляется ошибка $L$ (используя, например, MSE)
3. Обратное распространение ошибки - вычисление градиентов от выходного слоя к входному по следующей формуле: $\nabla{L}$
4. Корректирование весов
## Сети свёртки
Сверточные нейронные сети (Convolutional NN, CNN) - тип нейронных сетей, нацеленный на распознавание образов. Теоретическая основа предложена Яном Лекуном в 1988 году и схожа со зрительной корой. Структура является однонаправленной и многослойной. CNN является вариацией MLP для работы с данными, имеющими пространственную структуру (изображения).

Особенностью сети является то, что она использует операцию свёртки - умножения фрагмента данных на матрицу свёртки и суммирования результатов, после чего результат записывается в аналогичную позицию в выходных данных. Является трудной для понимания.

В отличии от MLP, связи в CNN ограничены небольшой матрицей весов. Также CNN может выполнять операцию подвыборки (субдискретизации) для уменьшения размерности карт признаков. В данной архитектуре считается, что информация о наличии искомого признака важнее точных координат признака. На последнем этапе классификации часто используются стандартные полносвязные слои

Важным плюсом является относительно небольшое количество требуемых параметров для работы из-за ограничения в размере матрицы весов.
# Сети на основе радиально-базисных функций
RBF-сети - сети, использующие радиально базисные функции для активации. Используются для приблизительных вычислений, классификации, прогнозирования. Выход сети выглядит как $$y(x)=\sum\limits^{M}_{i=1}w_{j}\phi_{j}(||x-c_{j}||)+w_{0}$$
где $c_{j}$ - центр RBF, $\phi_{j}$ - радиальная функция (обычно гауссова), $w_{0}$ - смещение
Обучение проходит в два этапа
1. Определение центров и ширины RBF - метод k-means (кластеризация) и выбор $\sigma_{j}$ (среднее расстояние между центрами)
2. Расчёт весов выходного слоя - решение линейной задачи (например, МНК)
## Сети регуляризации
Сети регуляризации - подход к построению моделей, добавляющий штраф за сложность модели с целью избегания переобучения. RBF-сети тесно связаны с теорией регуляризации Тихонова, где обучение сводится к минимизации $$min_{f}(\sum\limits^{n}_{i=1}(y_{i}-f(x_{i}))^{2}\lambda||Pf||^{2})$$
где $\lambda$ - параметр регуляризации, $P$ - оператор, штрафующий сложность функции (например, оператор Лапласа)

Решение задачи обучения может быть представлено в виде разложения по RBF $$f(x)=\sum\limits^{M}_{i=1}w_{i}\phi(||x-c_{i})$$
Данные сети уменьшают переобучение и повышают устойчивость сети к шуму
## Обобщенные сети на основе RBF
Обобщённые сети - расширения стандартных RBF-сетей для улучшения их универсальности, адаптивности и точности в задачах по типу регрессии, классификации и приближенных вычислений
### Виды
#### 1. Комбинированные RBF-архитектуры
Интеграция RBF-сетей с другими моделями позволяет достичь более высокой эффективности:
- RBF + MLP - радиально-базисный слой выполняет предварительное преобразование признаков перед их подачей в многослойный перцептрон
- RBF + SVM - использование адаптивной RBF-структуры в качестве ядра метода опорных векторов для улучшения классификации
#### 2. Динамические RBF-сети
В отличие от классических RBF с фиксированными параметрами, современные методы предлагают
- Самоорганизацию центров - применение алгоритмов типа SOM для оптимального размещения RBF-нейронов
- Обучение с подкреплением - автоматическую настройку параметров сети в процессе работы
#### 3. Гибридные RBF-модели с нечёткой логикой
Совмещение RBF-подхода с нечёткими системами повышает прозрачность модели:
- Нечёткие правила на базе RBF - интерпретация RBF-нейронов в виде лингвистических правил
- Адаптивные функции принадлежности - настройка параметров сети методами нечёткой оптимизации
#### 4. Глубокие RBF-архитектуры
Многоуровневые структуры расширяют возможности классических RBF:
- Иерархические RBF-сети - каскадное соединение нескольких RBF-слоёв для поэтапного обучения признаков
- RBF в свёрточных сетях - замена традиционных свёрточных операций на RBF-функции
#### 5. Вероятностные RBF-подходы
Статистическая интерпретация повышает надёжность модели:
- RBF в гауссовских процессах - использование радиальных функций в качестве ковариационных ядер
- Байесовские RBF-сети - учёт априорных распределений параметров для регуляризации модели
## Стратегии обучения
Обучение RBF-сетей состоит из:
1. Выбора центров RBF-функций (позиций нейронов скрытого слоя)
2. Определение ширины RBF-функций (параметра, влияющего на область активации)
3. Оптимизации весов выходного слоя (путем регрессии)
### Методы выбора центров
- Случайный выбор 
- Кластеризация (используя K-means и прочие) - центр RBF как центр кластера
- Карты Кохонена
- Ортогональные методы - итеративный выбор наиболее значимых центров
### Методы определения ширины
- Фиксированная - выбор константы
- Выбор ширины для каждого центра (например, на основе расстояний до ближайших соседей)
- Градиентный спуск
### Обучение
- Решение методом наименьших квадратов
- Градиентный спуск
- Регуляризация (с целью борьбы с переобучением) - $w=(\phi^{T}\phi+\lambda{I})_{1}\phi^{T}T$
# Машина опорных векторов
Машина опорных векторов (SVM) - частный случай регуляризации по Тихонову, также называемый методом классификатора с максимальным зазором. Основная идея - перевод исходных векторов в пространство более высокой размерности и поиск разделяющей гиперплоскости с наибольшим зазором. Алгоритм основан на допущении, что чем больше разница или расстояние между этими параллельными гиперплоскостями, тем меньше будет средняя ошибка классификатора.

## Задача распознавания образов
![[Assets/only-one-optimal.png]]
Распознавание образов - задача классификации объектов по их признакам. SVM используются в этой среде из-за способности эффективно разделять сложные данные.

Если объекты разных классов можно разделить гиперплоскостью, SVM находит оптимальную границу с максимальным зазором (на рисунке выше это L2). Это полезно для распознавания символов и геометрических признаков.

Если классы не делятся линейно, SVM использует переход от скалярных произведений к произвольным ядрам (kernel trick,  понятие, введенное Айзерманом, Браверманом и Розоноэром). Результирующий алгоритм крайне похож на алгоритм линейной классификации, с той лишь разницей, что каждое скалярное произведение в приведённых выше формулах заменяется нелинейной функцией ядра. В этом пространстве уже может существовать оптимальная разделяющая гиперплоскость. Так как размерность получаемого пространства может быть больше размерности исходного, то преобразование, сопоставляющее скалярные произведения, будет нелинейным, а значит функция, соответствующая в исходном пространстве оптимальной разделяющей гиперплоскости, будет также нелинейной.

Самыми частыми ядрами являются:
1. Полиномиальное однородное: $k(x, x')-(x\cdot{}x')^{d}$
2. Полиномиальное неоднородное: $k(x, x')=(x\cdot{}x'+1)^{d}$
3. RBF: $k(x, x')=exp(-\gamma||x-x'||^{2})$ при $\gamma\gt0$
4. RBF Гаусса: $k(x, x')=exp(\frac{-||x-x'||^{2}}{2\sigma{}^{2}})$
5. Сигмоид: $k(x, x')=tahn(\kappa{}x\cdot{}x'+c)$
## Задача нелинейной регрессии
Регрессия опорного вектора (SVR) - адаптация [[#Машина опорных векторов|SVM]] для задач регрессии, в рамках которой происходит поиск функции, которая приблизительно вычисляет данные с минимальной ошибкой в рамках $\epsilon$-полосы
### Основные идеи
1. Поиск функции регрессии $f(x)=w^{T}x+b$, минимизирующей ошибку предсказания при минимальных весах
2. Допустимая погрешность называется "трубкой" или "полосой" ($\epsilon{}-tube$). Внутри этой полосы ошибка не штрафуется
### Задача оптимизации 
$$min_{w,b} \frac{1}{2}||w||^{2}+C\sum\limits^{n}_{i=1}(\xi_{i}+\xi^{*}_{i})$$
при
$$y_{i}-w^{T}x+b\le{}\epsilon+\xi_{i}$$
$$(w^{T}x+b)-y_{i}\le{}\epsilon{}+\xi^{*}_{i}$$
$$\xi_{i},\xi^{*}_{i}\ge0$$
# Ассоциативные машины
Ассоциативная машина - алгоритм машинного обучения, основанный на разбиении задачи среди множества "экспертов", которые затем разбивают проблему на множество подпространств. Являются хорошими моделями для классификации и регрессии. Структурно они делятся на две основные категории - статические и динамические
## Усреднение по ансамблю
Усреднение по ансамблю - метод улучшения качества предсказаний статических машин с помощью объединения нескольких моделей-экспертов, которые сходятся к разным локальным минимумам поверхности ошибок.
![[Assets/Pasted image 20250527123330.png]]

Основными методами обучения являются
1. Бэггинг - обучение экспертов на различных выборках и усреднение их предсказаний
2. Стакинг - предсказания моделей усредняются с весами (например, линейной регрессией) и объединяются в один классификатор
3. Градиентный бустинг - итеративное обучение моделей для исправления новыми моделями ошибок старых
4. Байесовское усреднение - комбинирование предсказаний на основе их уверенности
## Методы усиления
Для улучшения эффективности работы статических ассоциативных машин существует метод "усиления" (boosting) - практика по улучшению работоспособности машины
### Усиление за счет фильтрации
Фильтрация примеров обучения различными версиями слабого алгоритма обучения. Предполагает доступность большого множества примеров, чтобы было из чего фильтровать
### Усиление за счет формирования подвыборок
Подвыборки составляются во время обучения с заданным распределением веростности. Ошибка вычисляется относительно множества примеров обучения
### Усиление путем перевзвешивания
Обработка фиксированного множества примеров, где слабый алгоритм обучения получает "взвешенные" примеры. Ошибка вычисляется относительно этих взвешенных примеров
## Подходы к построению – методы иерархического смешения мнений экспертов
Ассоциативные машины могут принимать решения "коллективно", комбинируя мнения нескольких экспертных систем. Ансамблированием называют иерархическое смешение мнений, которое позволяет комбинировать слабых "экспертов" в общую более мощную систему. Для интеграции использует так называемую сеть шлюзов, которая является посредником между сетями экспертов
![[Assets/hierarchy.png]]
### Основные методы
1. Байесовские иерархические модели - модели, основанные на использовании апостериорного распределения по теореме Байеса
2. Mixture of Experts - эксперты отвечают за свою область данных, иерархия через шлюзы
# Анализ главных компонентов
Анализ главных компонентов (PCA, Principal component analysis) - техника снижения размерности данных, используемая при анализе данных. Данные линейно трансформируются в новую систему координат так, что направления (главные компоненты), захватывающие наибольшую вариативность данных, легко определяются
## Структура
1. Нормализация - приведение всех данных к одному масштабу.
2. Построение ковариационной матрицы - выявление того, как признаки изменяются относительно друг друга. Ковариация вычисляется как $C=\frac{1}{n-1}X^{T}X$
3. Нахождение собственных значений и векторов - вычисление ковариации от $v$. Значения показывают важность компонента, векторы - направление новой оси
4. Сортировка компонентов по убыванию, так как убывание значений показывазывает убывание дисперсии
5. Выбор количества компонентов либо по критеорию Кайзера, либо на основе объяснённой дисперсии (т.е. так, чтобы сохранилось ~90% дисперсии)
6. Проецирование данных на новые оси путем создания матрицы проекции.
## Представления данных
Представление данных в PCA - способы интерпретации данных в контексте метода, т.е. описание того, как многомерные данные преобразуются и структурируются при снижении размерности.

Виды:
1. Геометрическая интерпретация - данные представлены точками вдоль оси, на которой дисперсия максимальна. Первая компонента - направление наибольшего разброса, вторая - ортогональное с наибольшим оставшимся разбросом
2. Статистическая интерпретация - минимизирование среднеквадратичной ошибки дисперсии
3. Алгебраическая интерпретация - сингулярное разложение таблицы данных, при котором собственные векторы задают направления компонент, собственные значения - их важность
## Сокращение размерности
Сокращение размерности данных - процесс уменьшения количества признаков в данных при сохранении максимально возможной информации, что является необходимым для уменьшения вычислительной сложности и оптимизацией работы модели, а также помогает визуализировать данные (так как размерность соответствует количеству измерений данных)

PCA сокращает размерность путем нахождение новых осей, вдоль которых дисперсия данных максимальна, а затем проецированием данных на подпространство этих осей
## На основе фильтра Хебба
Правило Хебба предполагает построение связей между нейронами при их совместной активации.
Вес связи между нейронами рассчитывается следующим образом:
$$\Delta{}w_{ij}=\eta{}\cdot{}x_{i}\cdot{}y_{i}$$
Если применить правило Хебба к одному нейрону с линейной активацией (и затем нормализовать веса), то веса сходятся к компоненту с максимальной дисперсией, что позволяет находить главные компоненты итеративно и добавляет в PCA нейроинспирированную реализацию
# Карты самоорганизации
Самоорганизующаяся карта Кохонена (SOM) - нейросеть с обучением без учителя для визуализации и кластеризации. Предложена Теуво Кохоненом в 1984 году.
## Этапы конкуренции
### Процессы конкуренции
Карта Кохонена может использовать [[#Конкурентное обучение]], что позволяет выделять ключевые паттерны данных при минимальном количестве измерений, сохраняя отношения между входными данными.
### Процессы кооперации
После конкуренции к входным данным адаптируются и победитель, и соседи, формируя топологически упорядоченную карту.

Для вычисления соседей используется функция соседства. Зачастую этой функцией является гауссовская функция вида $$h_{ci}(t)=\alpha(t)\cdot{}\exp(-\frac{||r_{c}-r_{i}||^{2}}{2\sigma{}^{2}(t)})$$
где $r_{i},r_{c}$ - координаты двух проверяемых узлов, $\sigma(t)$ - сомножитель, уменьшающий количество соседей с итерациями, $\alpha(t)$ - обучающий сомножитель, определяющий приближение значения векторов веса к наблюдению и являющийся размером шага

Данные действия позволяют сгладить веса и сохранить топологию карты.
### Процессы адаптации
Адаптацией называют процесс обновления весов нейронов-победителей и их соседей для улучшения соответствия входным данным моделей. Адаптация является конечным шагом обучения, обеспечивая точную настройку весов.

В рамках адаптации веса узлов меняются по формуле вида $w_{i}(t)=w_{i}(t-1)+h_{ci}(t)\cdot{}(x(t) - w_{i}(t-1))$, после чего уменьшаются $\sigma$ и $\alpha$

Данные шаги приводят к кластеризации и позволяют визуализировать данные
## Этапы адаптации
Процесс обучения карт Кохонена можно разделить на фазу упорядочивания и фазу сходимости (ordering phase, convergence phase)
### Фаза упорядочивания
В рамках этой фазы задачей является формирование топологически упорядоченной карты, в которой соседствующие нейроны реагируют на данные схожим образом. На этом этапе количество соседей высокое (примерно половина карты), высокая скорость обучения и большое количество итераций. В рамках этого этапа нейроны организуются в соответствии с распределением входных данных, а их веса корректируются таким образом, чтобы близкие точки оставались близкими
### Фаза сходимости
В рамках этой фазы карта начинает стабилизироваться. На этом этапе количество соседей снижается до 1-2 нейронов, скорость обучения падает для стабилизации результатов, а количество итераций повышается. В рамках этого этапа веса связей стабилизируются, ошибки квантования минимизируются, и карта начинает отражать статистические свойства данных
# Стохастические машины и нейродинамическое программирование
Стохастические машины - класс алгоритмов и вычислительных моделей, которые используют случайность для решения задач оптимизации, обучения и принятия решений. Применяются в задачах, в рамках которых детерминированные методы не являются эффективными. 

Нейродинамическое проектирование - объединение динамического программирования и нейронных сетей для решения задач оптимизации и управления. Данный подход применяется в задачах с такими пространствами состояний, где классическое динамическое программирования неприменимо
## Машина Больцмана
Машига Больцмана - стохастическая рекуррентная нейронная сеть, вдохновленная распределением Больцмана. Данные сети полносвязна и состоит из бинарных нейтронов. Для данной сети определяется понятие энергии, вычисляемое как $E=-\sum\limits_{i\lt{}j}w_{ij}s_{i}s_{j}-\sum\limits_{i}\theta_{i}s_{i}$, где $\theta$ - порог для нейрона, $s$ - бинарное состояние нейрона. Из этой формулы следует формула вероятности активации нейрона $P_{i}=\frac{1}{1+e^{\frac{-E_{k}}{t}}}$, где $t$ - уровень теплового шума в сети. Полезна в комбинаторных задачах, задачах классификации, фильтрации.
## Машина Гельмгольца
Машина Гельмгольца - стохастическая генеративная нейронная сеть, вдохновлённая концептом Энергии Гельмгольца. Машина состоит из двух сетей -
1. Модель распознавания, принимающая на вход данные, использующая приближенное апостериорное распределение и выводящая распределение скрытых переменных
2. Генеративная сеть, которая генерирует значения скрытых переменных и самих входных данных.
## Обучение с подкреплением
[[#Стохастические машины и нейродинамическое программирование|см. НДП]]

Обучение с подкреплением (RL, reinforcement learning) - область машинного обучения, в которой система обучается путем взаимодействия со средой. Состоит из агента (обучаемой системы), среды (внешнего мира), состояния (информации о текущем положении), возможных действий агента, а также наград и стратегий выбора действий.

RL использует НДП как основу некоторых методов
# Нелинейные динамические системы
Нелинейные динамические системы (НДС) - системы, выход которых изменяется нелинейно, то есть непропорционално изменению входных данных. Зачастую описываются дифференциальными и рекурентными уравнениями

К таким системам относятся биологические нейросети, экономические процессы
## Многослойные нейросетевые структуры прямого распространения
![[Assets/Pasted image 20250527152153.png]]
Многослойные нейронные сети прямого распространения (Feedforward MLP) - нейронные сети, архитектура которых состоит из стандартного входного и выходного слоя, а также скрытых слоев с нелинейными преобразованиями. Каждый слой сети является дискретной динамической системой, где состояние вычисляется как $s=\sigma(W_{i}h_{i}-1+b_{i})$. Нелинейность позволяет смоделировать нестандартные сложные зависимости, которые нельзя смоделировать линейно. Могут быть использованы для прогнозирования временных рядов, обработки естественного языка и медицинской диагностики
## Рекуррентные сети
Рекуррентные нейронные сети (RNN) - класс нейросетей, обладающих памятью за счет наличия циклов в графе вычислений.

Состояние слоя задается уравнением вида $h_{t}=\sigma{}(W_{h}h_{t-1}+w_{x}x_{t}+b)$, а в качестве функции активации часто используются tahn, сигмоида или ReLU
$$ReLU(x)=x^{+}=max(0,x)=\frac{x+|x|}{2}$$
Так как RNN по определению рекурентны, в нелинейной RNN функция активации вносит нелинейные искажения. Также, так как состояние зависит от предыдущего состояния сети, присутствует авторегрессия.

Данные сети используются для прогнозирования временных рядов и обработки естественного языка